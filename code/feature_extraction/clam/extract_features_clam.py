# Imports
import os
import time
import argparse
import numpy as np
import openslide
import h5py
from itertools import product

# PyTorch Imports
import torch
from torch.utils.data import DataLoader
from torchinfo import summary

# Project Imports
from data_utilities import DatasetAllBagsCLAM, WSISlideBagCLAMFPv2
from model_utilities import resnet50_baseline



# Function: Collate function for features
def collate_features(batch):
	img = torch.cat([item[0] for item in batch], dim = 0)
	coords = np.vstack([item[1] for item in batch])
	return [img, coords]



# Save HDF5 file
def save_hdf5(output_path, asset_dict, attr_dict=None, mode='a'):
    file = h5py.File(output_path, mode)
    for key, val in asset_dict.items():
        data_shape = val.shape
        if key not in file:
            data_type = val.dtype
            chunk_shape = (1, ) + data_shape[1:]
            maxshape = (None, ) + data_shape[1:]
            dset = file.create_dataset(key, shape=data_shape, maxshape=maxshape, chunks=chunk_shape, dtype=data_type)
            dset[:] = val
            if attr_dict is not None:
                if key in attr_dict.keys():
                    for attr_key, attr_val in attr_dict[key].items():
                        dset.attrs[attr_key] = attr_val
        else:
            dset = file[key]
            dset.resize(len(dset) + data_shape[0], axis=0)
            dset[-data_shape[0]:] = val
    file.close()
    return output_path



# Function: Compute WSI Features using CLAM-based approach (with ResNet50)
def compute_wsi_features_clam(output_path, file_path, wsi, model, transform, device, batch_size=8, verbose=False, pretrained=True, custom_downsample=1, target_patch_size=-1, num_workers=0, pin_memory=False):
    
    """
    Args:
        file_path: directory of bag (.h5 file)
        wsi: the path to the WSI (.h5 file)
        model: PyTorch model
        batch_size: batch_size for computing features in batches
        verbose: provide feedback in the command line
        pretrained: use weights pretrained on imagenet
        custom_downsample: custom defined downscale factor of image patches
        target_patch_size: custom defined, rescaled image size before embedding
    """



    # Read WSI information	
    dataset = WSISlideBagCLAMFPv2(
        file_path=file_path,
        wsi=wsi,
        pretrained=pretrained,
        custom_downsample=custom_downsample,
        target_patch_size=target_patch_size,
        transform=transform,
        verbose=verbose,
    )


    # Create dataloader
    dataloader = DataLoader(
        dataset=dataset,
        batch_size=batch_size,
        num_workers=num_workers, 
        pin_memory=pin_memory,
        collate_fn=collate_features
    )


    # Set hdf5 file mode to write when the processing begins
    mode = 'w'
    for _, (batch, _) in enumerate(dataloader):
        with torch.no_grad():	
            
            # Get batch of data
            batch = batch.to(device, non_blocking=True)
            
            # Extract features
            features = model(batch)
            features = features.cpu().numpy()
            save_hdf5(
                output_path,
                asset_dict={'features': features}, 
                attr_dict=None, 
                mode=mode
            )
            mode = 'a'

    return



if __name__ == '__main__':

    # CLI
    parser = argparse.ArgumentParser(description='CLAM: WSI Feature Extraction.')
    parser.add_argument('--data_idx_start', type=int, required=False, help="The data start index to extract features.")
    parser.add_argument('--data_idx_stop', type=int, required=False, help="The stop index to extract features.")
    parser.add_argument('--gpu_id', type=int, default=0, help="The ID of the GPU we will use to run the program.")
    parser.add_argument('--data_h5_dir', type=str, required=True, help="The directory of the .h5 files generated by the previous step (i.e., create_patches_fp).")
    parser.add_argument('--process_list_csv_path', type=str, required=True, help="The path to the .csv file generated by the previous step (i.e., create_patches_fp).")
    parser.add_argument('--feat_dir', type=str, required=True, help="The directory to save these features.")
    parser.add_argument('--batch_size', type=int, default=256)
    parser.add_argument('--auto_skip', default=False, action='store_true', help="Skip files (features) that are already in the directory.")
    parser.add_argument('--custom_downsample', type=int, default=1)
    parser.add_argument('--target_patch_size', type=int, default=-1)
    parser.add_argument('--verbose', default=False, action='store_true')
    parser.add_argument('--num_workers', type=int, help="The <num_workers> argument for the dataloader.")
    parser.add_argument('--pin_memory', action='store_true', help="The <pin_memory> argument for the dataloader.")
    parser.add_argument('--transform', type=str, required=False, default=None, choices=["HEDAugmentationTransform"], help="The type of transform to apply in case of data augmentation.")
    parser.add_argument('--lower_b', type=float, required=False, help="The lower bound for the transformations that require a certain type of range.")
    parser.add_argument('--upper_b', type=float, required=False, help="The upper bound for the transformations that require a certain type of range.")
    parser.add_argument('--num_b', type=int, required=False, help="The number of steps for the transformations that require a certain type of range.")
    parser.add_argument('--n_iterations', type=int, required=False, default=0, help="The number of iterations to apply the transforms.")
    parser.add_argument('--seed', type=int, required=False, default=None, help="The random seedcfor the stochastic processes.")
    args = parser.parse_args()



    # Get the file of the .CSV file that contains the list of .h5 files (process_list_csv_path from the previous step)
    csv_path = args.process_list_csv_path

    # Generate a list of WSI .h5 files
    bags_dataset = DatasetAllBagsCLAM(csv_path)

    # Load model and get device
    device = torch.device(f'cuda:{args.gpu_id}') if torch.cuda.is_available() else torch.device('cpu')
    model = resnet50_baseline(pretrained=True)
    model = model.to(device)
    model.eval()
    
    # Print summary of the model
    if args.verbose:
        summary(model)


    # TODO/FIXME: Implement/fix Multi-GPU
    # if (torch.cuda.device_count() > 1) and (args.number_of_gpus > 1):
    # 	model = nn.DataParallel(model)
    
    # Get transforms
    if args.transform:
        if args.transform == "HEDAugmentationTransform":
            
            # Create a list for the different transform versions
            transform_versions_list = list()

            if args.n_iterations == 1 and args.seed is not None:
                transform = HEDAugmentationTransform(seed=args.seed)
                transform_versions_list.append(transform)

                # Updated number of iterations and the names of the PT files
                n_iterations = len(transform_versions_list)
                h5_fnames = [f"hed_s{args.seed}.h5"]
            
            elif args.num_b is not None and args.seed is None:
                
                # Iterate through the possible seeds
                for seed in range(args.num_b):
                    if args.lower_b is not None and args.upper_b is not None:

                        assert args.lower_b < args.upper_b
                        transform = HEDAugmentationTransform(
                            lower=args.lower_b,
                            upper=args.upper_b,
                            seed=seed
                        )
                    else:
                        transform = HEDAugmentationTransform(seed=seed)
                    transform_versions_list.append(transform)
                
                # Updated number of iterations and the names of the PT files
                n_iterations = len(transform_versions_list)
                h5_fnames = [f"hed_rs{i}.h5" for i in range(n_iterations)]
                
            else:
                assert args.lower_b is not None and args.upper_b is not None and args.num_b is not None and args.seed is not None
                
                # Here the number of iterations will dictate the number of steps
                start = args.lower_b
                stop = args.upper_b
                num = args.num_b
                
                assert stop > start

                hed_values = list(np.linspace(start=start, stop=stop, num=num, endpoint=True))
                hed_combs_rep = product(hed_values, hed_values, hed_values)
                hed_combs_list = list()
                for value in hed_combs_rep:
                    if not(value[0] == 0 and value[1] == 0 and value[2] == 0):
                        hed_combs_list.append(value)
                # print(hed_combs_list)
                # print(len(hed_combs_list))

                for hed_offsets in hed_combs_list:
                    transform_versions_list.append(HEDAugmentationTransform(hed_offsets=hed_offsets))


                # Updated number of iterations and the names of the PT files
                n_iterations = len(transform_versions_list)
                h5_fnames = [f"hed_so{i}.h5" for i in range(n_iterations)]

    else:

        assert args.n_iterations == 1
        transform = None
        h5_fnames = ["original.h5"]
        n_iterations = args.n_iterations


    if args.verbose:
        print(f"Using transform: {args.transform}")


    # Iterate through the dataset
    if args.data_idx_start is not None and args.data_idx_stop is not None:
        bag_candidate_indices = [i for i in range(args.data_idx_start, args.data_idx_stop)]
    else:
        bag_candidate_indices = [i for i in range(len(bags_dataset))]
    # print(len(bag_candidate_indices))
    # print(bag_candidate_indices)
    

    for bag_candidate_idx in bag_candidate_indices:

        # Get Slide ID
        slide_file_path = bags_dataset[bag_candidate_idx]
        slide_name = slide_file_path.split('/')[-1]
        slide_ext = slide_name.split('.')[-1]
        slide_ext = f'.{slide_ext}'
        slide_id = slide_name.split(slide_ext)[0]
        
        # Get the .h5 file
        bag_name = slide_id+'.h5'
        
        # Build the path
        h5_file_path = os.path.join(args.data_h5_dir, 'patches', bag_name)
        assert os.path.exists(h5_file_path)
        

        # Verbose
        if args.verbose:
            print(f'Progress: {bag_candidate_idx+1}/{len(bag_candidate_indices)}')
            print('Slide ID: ', slide_id)



        # Verbose (time elapsed)
        if args.verbose:
            time_start = time.time()
        

        # Open WSI
        # TODO: Updated this in the code afterwards
        slide_file_path = slide_file_path.replace('cluster', 'vast')
        assert os.path.exists(slide_file_path)
        wsi = openslide.open_slide(slide_file_path)
        
        # Extract features
        for i in range(n_iterations):

            # Get the Slide ID directory to save these features
            wsi_features_dir = os.path.join(args.feat_dir, f'{slide_id}')
            if not os.path.isdir(wsi_features_dir):
                os.makedirs(wsi_features_dir)
            
            # Save features
            h5_fname = h5_fnames[i]
            output_path = os.path.join(wsi_features_dir, h5_fname)
            
            # Remove old .pt fles
            pt_fname = h5_fname.replace('.h5', '.pt')
            if os.path.exists(os.path.join(wsi_features_dir, pt_fname)):
                os.remove(os.path.join(wsi_features_dir, pt_fname))
            
            # Get transform
            transform = transform_versions_list[i]

            compute_wsi_features_clam(
                output_path=output_path,
                file_path=h5_file_path,
                wsi=wsi,
                model=model,
                transform=[transform],
                device=device,
                batch_size=args.batch_size,
                verbose=args.verbose,
                custom_downsample=args.custom_downsample,
                target_patch_size=args.target_patch_size,
                num_workers=args.num_workers,
                pin_memory=args.pin_memory
            )
            

            # Verbose (time elapsed)
            if args.verbose:
                time_elapsed = time.time() - time_start
                print(f'Computing features for {slide_id} took {time_elapsed}s.')
