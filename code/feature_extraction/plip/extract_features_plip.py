# Imports
import os
import time
import argparse
import numpy as np
import h5py
import openslide

# PyTorch Imports
import torch
from torch.utils.data import DataLoader
from torchinfo import summary

# Hugging Face Imports
from transformers import CLIPProcessor

# Project Imports (and PLIP)
from data_utilities import Dataset_All_Bags, WSISlideBagPLIP
from model_utilities import PLIP



# Save HDF5 file
def save_hdf5(output_path, asset_dict, attr_dict=None, mode='a'):
    file = h5py.File(output_path, mode)
    for key, val in asset_dict.items():
        data_shape = val.shape
        if key not in file:
            data_type = val.dtype
            chunk_shape = (1, ) + data_shape[1:]
            maxshape = (None, ) + data_shape[1:]
            dset = file.create_dataset(key, shape=data_shape, maxshape=maxshape, chunks=chunk_shape, dtype=data_type)
            dset[:] = val
            if attr_dict is not None:
                if key in attr_dict.keys():
                    for attr_key, attr_val in attr_dict[key].items():
                        dset.attrs[attr_key] = attr_val
        else:
            dset = file[key]
            dset.resize(len(dset) + data_shape[0], axis=0)
            dset[-data_shape[0]:] = val
    file.close()
    return output_path



# Function: Collate features for PLIP
def collate_features_plip(batch):
    img = torch.cat([item[0] for item in batch], dim = 0)
    coords = np.vstack([item[1] for item in batch])
    return [img, coords]



# Function: Compute WSI Features w/ PLIP
def compute_wsi_features_plip(file_path, wsi, plip_preprocessor, plip_model, transform, batch_size, verbose=False, custom_downsample=1, target_patch_size=-1, num_workers=0, pin_memory=True):
    
    """
    Arguments:
        file_path: directory of bag (.h5 file)
        output_path: directory to save computed features (.h5 file)
        wsi: the path to the WSI (.h5 file)
        plip_model: PLIP model
        batch_size: batch_size for computing features in batches
        verbose: provide feedback in the command line
        custom_downsample: custom defined downscale factor of image patches
        target_patch_size: custom defined, rescaled image size before embedding
    """



    # Read WSI information and create a WSI dataset
    dataset = WSISlideBagPLIP(
        file_path=file_path,
        wsi=wsi,
        custom_downsample=custom_downsample,
        target_patch_size=target_patch_size,
        plip_preprocessor=plip_preprocessor,
        verbose=verbose,
        transform=transform
    )

    # Create a dataloader
    dataloader = DataLoader(
        dataset=dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        collate_fn=collate_features_plip
    )


    # Verbose
    if verbose:
        print(f'Processing {file_path}: total of {len(dataloader)} batches.')


    # Set hdf5 file mode to write when the processing begins
    mode = 'w'
    features = None
    for count, (images, coords) in enumerate(dataloader):
        with torch.no_grad():	

            # Extract features
            features_ = plip_model.encode_images(
                images=images,
                batch_size=batch_size,
                num_workers=num_workers,
                pin_memory=pin_memory
            )

            if features is None:
                features = features_
            else:
                features = np.concatenate((features, features_), axis=0)

            # TODO: Erase uppon testing
            # Create and/or save/append into hdf5
            # asset_dict = {'features': features, 'coords': coords}
            # save_hdf5(output_path, asset_dict, attr_dict=None, mode=mode)
            # mode = 'a'

    return features



if __name__ == '__main__':

    # CLI
    parser = argparse.ArgumentParser(description='PLIP: WSI Feature Extraction.')
    parser.add_argument('--gpu_id', type=int, default=0, help="The ID of the GPU we will use to run the program.")
    parser.add_argument('--data_h5_dir', type=str, required=True, help="The directory of the .h5 files generated by the previous step (i.e., create_patches_fp).")
    parser.add_argument('--process_list_csv_path', type=str, required=True, help="The path to the .csv file generated by the previous step (i.e., create_patches_fp).")
    parser.add_argument('--feat_dir', type=str, required=True, help="The directory to save these features.")
    parser.add_argument('--batch_size', type=int, default=256)
    parser.add_argument('--custom_downsample', type=int, default=1)
    parser.add_argument('--target_patch_size', type=int, default=-1)
    parser.add_argument('--verbose', default=False, action='store_true')
    parser.add_argument('--num_workers', type=int, help="The <num_workers> argument for the dataloader.")
    parser.add_argument('--pin_memory', action='store_true', help="The <pin_memory> argument for the dataloader.")
    parser.add_argument('--transform', type=str, required=False, default=None, choices=["HEDAugmentationTransform"], help="The type of transform to apply in case of data augmentation.")
    parser.add_argument('--n_iterations', type=int, required=False, default=1, help="The number of iterations to apply the transforms.")
    parser.add_argument('--seed', type=int, required=False, default=42, help="The random seedcfor the stochastic processes.")
    args = parser.parse_args()



    # TODO: Erase uppon testing
    # Generate feature directories
    # for sub_feat_dir in ('pt_files', 'h5_files'):
    #     if not os.path.isdir(os.path.join(args.feat_dir, sub_feat_dir)):
    #         os.makedirs(os.path.join(args.feat_dir, sub_feat_dir), exist_ok=True)

    
    # TODO: Erase uppon testing
    # Save experiment arguments
    # with open(os.path.join(args.data_h5_dir, "args_extract_features_fp.txt"), "w") as f:
    #     f.write(str(args))


    # TODO: Erase uppon testing
    # Directory for .pt files
    # dest_files = os.listdir(os.path.join(args.feat_dir, 'pt_files'))


    # Get the file of the .CSV file that contains the list of .h5 files (process_list_csv_path from the previous step)
    csv_path = args.process_list_csv_path

    # Generate a list of WSI .h5 files
    bags_dataset = Dataset_All_Bags(csv_path)

    # Load model and get device
    device = torch.device(f'cuda:{args.gpu_id}') if torch.cuda.is_available() else torch.device('cpu')
    plip_preprocessor = CLIPProcessor.from_pretrained('vinid/plip')
    plip_model = PLIP(model_name='vinid/plip', device=device)
    plip_model.model.to(device)
    plip_model.model.eval()
    
    # Print summary of the model
    if args.verbose:
        summary(plip_model.model)


    # TODO/FIXME: Implement/fix Multi-GPU
    # if (torch.cuda.device_count() > 1) and (args.number_of_gpus > 1):
    # 	model = nn.DataParallel(model)
    

    # Get transforms
    if args.transform:
        if args.transform == "HEDAugmentationTransform":

            assert args.n_iterations >= 1 and args.seed is not None
            transform = HEDAugmentationTransform(seed=args.seed)
            pt_fnames = [f"hed_{i}.pt" for i in range(args.n_iterations)]

    else:

        assert args.n_iterations == 1
        transform = None
        pt_fnames = ["original.pt"]


    if args.verbose:
        print(f"Using transform: {args.transform}")


    # Iterate through the dataset
    total = len(bags_dataset)
    for bag_candidate_idx in range(total):

        # Get Slide ID
        slide_file_path = bags_dataset[bag_candidate_idx]
        slide_name = slide_file_path.split('/')[-1]
        slide_ext = slide_name.split('.')[-1]
        slide_ext = f'.{slide_ext}'
        slide_id = slide_name.split(slide_ext)[0]
        
        # Get the .h5 file
        bag_name = slide_id+'.h5'
        
        # Build the path
        h5_file_path = os.path.join(args.data_h5_dir, 'patches', bag_name)
        assert os.path.exists(h5_file_path)

        # Verbose
        if args.verbose:
            print(f'\nProgress: {bag_candidate_idx+1}/{total}')
            print('Slide ID: ', slide_id)


        # TODO: Erase uppon review
        # Build output path
        # output_path = os.path.join(args.feat_dir, 'h5_files', bag_name)
        

        # Verbose (time elapsed)
        if args.verbose:
            time_start = time.time()
        

        # Open WSI
        assert os.path.exists(slide_file_path)
        wsi = openslide.open_slide(slide_file_path)


        # Extract features
        for i in range(args.n_iterations):

            features = compute_wsi_features_plip(
                file_path=h5_file_path,
                wsi=wsi,
                plip_preprocessor=plip_preprocessor,
                plip_model=plip_model,
                transform=transform,
                batch_size=args.batch_size,
                verbose=args.verbose,
                custom_downsample=args.custom_downsample,
                target_patch_size=args.target_patch_size,
                num_workers=args.num_workers,
                pin_memory=args.pin_memory
            )
            

            # Verbose (time elapsed)
            if args.verbose:
                time_elapsed = time.time() - time_start
                print(f'\nComputing features for {slide_id} took {time_elapsed}s.')
            
            
            # TODO: Erase uppon review
            # Get .h5 file and features
            # file = h5py.File(output_path, "r")
            # features = file['features'][:]
            

            # Verbose
            if args.verbose:
                print('Features shape: ', features.shape)
                # print('Coordinates shape: ', file['coords'].shape)
            
            
            # Save results into .pt file
            features = torch.from_numpy(features)

            # Get the Slide ID directory to save these features
            wsi_features_dir = os.path.join(args.feat_dir, f'{slide_id}')
            if not os.path.isdir(wsi_features_dir):
                os.makedirs(wsi_features_dir)
            
            # Save features
            pt_fname = pt_fnames[i]
            torch.save(
                obj=features,
                f=os.path.join(wsi_features_dir, pt_fname)
            )


            # TODO: Erase uppon review
            # bag_base, _ = os.path.splitext(bag_name)
            # torch.save(features, os.path.join(args.feat_dir, 'pt_files', bag_base+'.pt'))


            # TODO: Erase uppon review
            # Delete .h5 file (for storage efficiency purposes)
            # if os.path.exists(output_path):
            #     os.remove(output_path)
